import React, { useState, useRef, useEffect } from 'react';
import { FaceDetector, FilesetResolver } from '@mediapipe/tasks-vision';

const containerStyle = { maxWidth: '600px', margin: '0 auto', padding: '20px', fontFamily: '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif' };
const buttonStyle = { padding: '12px 24px', margin: '5px', background: '#007bff', color: '#fff', border: 'none', borderRadius: '8px', fontSize: '16px', fontWeight: 'bold', cursor: 'pointer', width: '100%' };
const inputStyle = { padding: '10px', borderRadius: '8px', border: '1px solid #ccc', width: '100%', boxSizing: 'border-box', fontSize: '16px' };
const controlPanelStyle = { margin: '15px 0', padding: '15px', background: '#e9ecef', borderRadius: '12px', display: 'flex', flexDirection: 'column', gap: '15px' };

function App() {
  // === çŠ¶æ€ç®¡ç† ===
  const [detector, setDetector] = useState(null);
  const [videoSrc, setVideoSrc] = useState(null);
  
  // UI é€‰é¡¹
  const [maskMode, setMaskMode] = useState('emoji'); 
  const [maskSrc, setMaskSrc] = useState(null); 
  const [emojiChar, setEmojiChar] = useState('ğŸ˜');
  const [exportFormat, setExportFormat] = useState('mp4'); // é»˜è®¤ MP4

  // è¿½è¸ªè®¾ç½®
  const [trackingMode, setTrackingMode] = useState('single'); // 'single' æˆ– 'multi'
  const [maxFaces, setMaxFaces] = useState(2); // å¤šäººæ¨¡å¼ä¸‹çš„äººæ•°é™åˆ¶

  const [isProcessing, setIsProcessing] = useState(false);
  const [status, setStatus] = useState("æ­£åœ¨åŠ è½½ AI æ¨¡å‹...");
  const [downloadUrl, setDownloadUrl] = useState(null);

  // === Refs (ä¸è§¦å‘æ¸²æŸ“çš„å˜é‡) ===
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const maskImgRef = useRef(null);
  const chunksRef = useRef([]);
  const rafIdRef = useRef(null); // åŠ¨ç”»å¾ªç¯IDï¼Œç”¨äºå¼ºåˆ¶åœæ­¢

  // è¿½è¸ªæ•°æ® Refs
  const singleFaceRef = useRef(null); // å•äººæ¨¡å¼ä¸“ç”¨
  const multiFacesRef = useRef([]);   // å¤šäººæ¨¡å¼ä¸“ç”¨
  
  // çŠ¶æ€åŒæ­¥ Refs (ç”¨äºåœ¨å¾ªç¯ä¸­è·å–æœ€æ–° State)
  const settingsRef = useRef({
    maskMode: 'emoji',
    emojiChar: 'ğŸ˜',
    trackingMode: 'single',
    maxFaces: 2
  });

  const audioCtxRef = useRef(null);
  const sourceNodeRef = useRef(null);
  const destNodeRef = useRef(null);
  const initLockRef = useRef(false);

  // 1. åˆå§‹åŒ– AI
  useEffect(() => {
    if (initLockRef.current) return;
    initLockRef.current = true;

    const initAI = async () => {
      console.log("ğŸš€ åˆå§‹åŒ– AI...");
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        const faceDetector = await FaceDetector.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          minDetectionConfidence: 0.3,
          minSuppressionThreshold: 0.3 
        });
        setDetector(faceDetector);
        setStatus("âœ… AI å°±ç»ªï¼è¯·å¯¼å…¥è§†é¢‘");
      } catch (err) {
        setStatus(`âŒ æ¨¡å‹åŠ è½½å¤±è´¥: ${err.message}`);
      }
    };
    initAI();
  }, []);

  // åŒæ­¥è®¾ç½®åˆ° Ref
  useEffect(() => {
    settingsRef.current = { maskMode, emojiChar, trackingMode, maxFaces };
  }, [maskMode, emojiChar, trackingMode, maxFaces]);

  // é‡ç½®æ’­æ”¾å™¨çŠ¶æ€ (è§£å†³å¡æ­»é—®é¢˜)
  const resetPlayerState = () => {
    if (rafIdRef.current) cancelAnimationFrame(rafIdRef.current);
    if (videoRef.current) {
        videoRef.current.pause();
        videoRef.current.currentTime = 0;
    }
    setDownloadUrl(null);
    setIsProcessing(false);
    chunksRef.current = [];
    singleFaceRef.current = null;
    multiFacesRef.current = [];
    setStatus("å·²é‡ç½®ï¼Œå‡†å¤‡å°±ç»ª");
  };

  const handleVideoUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
      resetPlayerState(); // å¯¼å…¥æ–°è§†é¢‘æ—¶å¼ºåˆ¶é‡ç½®
      setVideoSrc(URL.createObjectURL(file));
      setStatus("è§†é¢‘å·²åŠ è½½");
    }
  };

  const handleMaskUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
      const img = new Image();
      img.src = URL.createObjectURL(file);
      img.onload = () => { maskImgRef.current = img; };
      setMaskSrc(img.src);
    }
  };

  const startProcessing = async () => {
    // å¼ºåˆ¶é‡ç½®ä¸Šä¸€è½®çŠ¶æ€
    if (rafIdRef.current) cancelAnimationFrame(rafIdRef.current);
    
    if (!detector || !videoRef.current) {
      alert("è¯·ç­‰å¾…èµ„æºåŠ è½½");
      return;
    }
    if (maskMode === 'image' && !maskImgRef.current) {
        alert("è¯·å…ˆä¸Šä¼ é®æŒ¡å›¾ç‰‡");
        return;
    }

    const video = videoRef.current;
    
    // ç¡®ä¿è§†é¢‘å…ƒæ•°æ®åŠ è½½
    if (video.readyState < 2) {
        setStatus("æ­£åœ¨ç¼“å†²è§†é¢‘...");
        await new Promise(resolve => {
            video.onloadeddata = resolve;
            // ç®€å•çš„è¶…æ—¶ä¿é™©
            setTimeout(resolve, 2000); 
        });
    }

    setIsProcessing(true);
    setStatus("ğŸš€ å¼•æ“å¯åŠ¨ä¸­...");
    setDownloadUrl(null);
    chunksRef.current = [];
    singleFaceRef.current = null;
    multiFacesRef.current = [];

    const canvas = canvasRef.current;
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;
    const ctx = canvas.getContext('2d');

    // === éŸ³é¢‘å¤„ç† (å¸¦æ¸…ç†é€»è¾‘) ===
    try {
        if (!audioCtxRef.current) audioCtxRef.current = new (window.AudioContext || window.webkitAudioContext)();
        const audioCtx = audioCtxRef.current;
        if (audioCtx.state === 'suspended') await audioCtx.resume();
        
        // æ–­å¼€æ—§è¿æ¥ï¼Œé˜²æ­¢é‡å 
        if (sourceNodeRef.current) {
            try { sourceNodeRef.current.disconnect(); } catch(e){}
        }
        
        sourceNodeRef.current = audioCtx.createMediaElementSource(video);
        if (!destNodeRef.current) destNodeRef.current = audioCtx.createMediaStreamDestination();
        sourceNodeRef.current.connect(destNodeRef.current);
    } catch (e) { console.warn("éŸ³é¢‘è­¦å‘Š:", e); }

    const canvasStream = canvas.captureStream(30); 
    if (destNodeRef.current) {
        const audioTrack = destNodeRef.current.stream.getAudioTracks()[0];
        if (audioTrack) canvasStream.addTrack(audioTrack);
    }

    // === æ ¼å¼é€‰æ‹©é€»è¾‘ (MP4ä¼˜å…ˆ) ===
    let mimeType = '';
    if (exportFormat === 'mp4') {
        // å°è¯• MP4
        if (MediaRecorder.isTypeSupported('video/mp4; codecs="avc1.42E01E, mp4a.40.2"')) mimeType = 'video/mp4; codecs="avc1.42E01E, mp4a.40.2"';
        else if (MediaRecorder.isTypeSupported('video/mp4')) mimeType = 'video/mp4';
        else mimeType = 'video/webm; codecs=vp9'; // å›é€€
    } else {
        // å°è¯• WebM
        if (MediaRecorder.isTypeSupported('video/webm; codecs=vp9')) mimeType = 'video/webm; codecs=vp9';
        else mimeType = 'video/webm';
    }
    
    console.log(`ä½¿ç”¨æ ¼å¼: ${mimeType}`);

    let recorder;
    try {
        recorder = new MediaRecorder(canvasStream, { mimeType, videoBitsPerSecond: 3000000 }); // 3Mbps ç ç‡
    } catch (e) { 
        console.error(e);
        recorder = new MediaRecorder(canvasStream); // æœ€åçš„ä¿åº•
    }
    
    recorder.ondataavailable = (e) => { if (e.data && e.data.size > 0) chunksRef.current.push(e.data); };
    recorder.onstop = () => {
      const blob = new Blob(chunksRef.current, { type: mimeType.split(';')[0] });
      if (blob.size === 0) { alert("ç”Ÿæˆå¤±è´¥ï¼šæ–‡ä»¶å¤§å°ä¸º0"); setIsProcessing(false); return; }
      setDownloadUrl(URL.createObjectURL(blob));
      setIsProcessing(false);
      setStatus("âœ… å¤„ç†å®Œæˆï¼");
      video.pause(); video.muted = false;
      canvasStream.getTracks().forEach(track => track.stop()); // åœæ­¢æµ
    };

    recorder.start(100); 
    
    try {
        video.currentTime = 0; video.muted = false; 
        await video.play();
        processFrame(video, ctx, recorder);
    } catch (e) {
        setStatus(`æ’­æ”¾é”™è¯¯: ${e.message}`);
        setIsProcessing(false);
        recorder.stop();
    }
  };

  const processFrame = (video, ctx, recorder) => {
    if (video.ended || video.paused) {
      if (recorder.state === 'recording') recorder.stop();
      return;
    }

    const canvas = ctx.canvas;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const startTimeMs = performance.now();
    let detections = [];
    try { 
        if (detector) {
            const res = detector.detectForVideo(video, startTimeMs);
            detections = res.detections || [];
        }
    } catch(e) {}

    // è¯»å–æœ€æ–°è®¾ç½®
    const { maskMode: curMaskMode, emojiChar: curEmoji, trackingMode: curTrackingMode, maxFaces: curMaxFaces } = settingsRef.current;

    // === ğŸ”¥ æ ¸å¿ƒåˆ†æ”¯é€»è¾‘ ===
    if (curTrackingMode === 'single') {
        // --- æ–¹æ¡ˆ A: æè‡´å•äºº (æ­»æ­»æ‰’ä½) ---
        handleSinglePersonMode(detections);
        drawFaces(ctx, [singleFaceRef.current], curMaskMode, curEmoji);
    } else {
        // --- æ–¹æ¡ˆ B: æ™ºèƒ½å¤šäºº (Top N) ---
        handleMultiPersonMode(detections, curMaxFaces);
        drawFaces(ctx, multiFacesRef.current, curMaskMode, curEmoji);
    }

    rafIdRef.current = requestAnimationFrame(() => processFrame(video, ctx, recorder));
  };

  // === é€»è¾‘ A: å•äººæ­»é”æ¨¡å¼ ===
  const handleSinglePersonMode = (detections) => {
      // 1. æ‰¾ç”»é¢é‡Œæœ€å¤§çš„ä¸€å¼ è„¸ (æ— è§†å…¶ä»–çš„)
      let bestFace = null;
      let maxArea = 0;

      detections.forEach(det => {
          const { width, height } = det.boundingBox;
          const area = width * height;
          if (area > maxArea) {
              maxArea = area;
              bestFace = det.boundingBox;
          }
      });

      // 2. å¦‚æœæ‰¾åˆ°äº†ï¼Œè¿›è¡Œå¹³æ»‘æ›´æ–°
      if (bestFace) {
          if (singleFaceRef.current) {
              const old = singleFaceRef.current;
              const alpha = 0.4; // æ©¡çš®ç­‹ç³»æ•°
              
              // å¹³æ»‘æ›´æ–°
              old.x = old.x * (1-alpha) + bestFace.originX * alpha;
              old.y = old.y * (1-alpha) + bestFace.originY * alpha;
              old.w = old.w * (1-alpha) + bestFace.width * alpha;
              old.h = old.h * (1-alpha) + bestFace.height * alpha;
              
              // æ›´æ–°æƒ¯æ€§é€Ÿåº¦
              old.vx = old.x - (singleFaceRef.current.x); // è¿™é‡Œè¿‘ä¼¼
              old.vy = old.y - (singleFaceRef.current.y);
              
              old.missedFrames = 0;
          } else {
              // ç¬¬ä¸€æ¬¡å‘ç°
              singleFaceRef.current = {
                  x: bestFace.originX, y: bestFace.originY,
                  w: bestFace.width, h: bestFace.height,
                  vx: 0, vy: 0, missedFrames: 0
              };
          }
      } else if (singleFaceRef.current) {
          // 3. æ²¡æ‰¾åˆ°ï¼Œå¯åŠ¨æƒ¯æ€§é¢„æµ‹
          const old = singleFaceRef.current;
          old.missedFrames++;
          if (old.missedFrames < 30) { // å…è®¸é¢„æµ‹30å¸§
              old.vx *= 0.9;
              old.vy *= 0.9;
              old.x += old.vx;
              old.y += old.vy;
          } else {
              singleFaceRef.current = null; // ä¸¢å¤ªä¹…ï¼Œæ”¾å¼ƒ
          }
      }
  };

  // === é€»è¾‘ B: å¤šäºº Top N æ¨¡å¼ ===
  const handleMultiPersonMode = (detections, maxN) => {
      let trackedFaces = multiFacesRef.current;
      trackedFaces.forEach(f => f.updated = false);

      // è´ªå©ªåŒ¹é…
      detections.forEach(det => {
          const bbox = det.boundingBox;
          const cx = bbox.originX + bbox.width/2;
          const cy = bbox.originY + bbox.height/2;

          let bestMatch = null;
          let minDist = 200; // åŒ¹é…é˜ˆå€¼

          trackedFaces.forEach(face => {
              const dist = Math.sqrt(Math.pow(cx - (face.x + face.w/2), 2) + Math.pow(cy - (face.y + face.h/2), 2));
              if (dist < minDist) {
                  minDist = dist;
                  bestMatch = face;
              }
          });

          if (bestMatch && !bestMatch.updated) {
              const alpha = 0.4;
              bestMatch.x = bestMatch.x * (1-alpha) + bbox.originX * alpha;
              bestMatch.y = bestMatch.y * (1-alpha) + bbox.originY * alpha;
              bestMatch.w = bestMatch.w * (1-alpha) + bbox.width * alpha;
              bestMatch.h = bestMatch.h * (1-alpha) + bbox.height * alpha;
              bestMatch.updated = true;
              bestMatch.missedFrames = 0;
          } else {
              // æ–°äºº
              trackedFaces.push({
                  x: bbox.originX, y: bbox.originY, w: bbox.width, h: bbox.height,
                  vx: 0, vy: 0, missedFrames: 0, updated: true
              });
          }
      });

      // æ¸…ç†ä¸¢å¤±çš„
      trackedFaces = trackedFaces.filter(f => {
          if (!f.updated) {
              f.missedFrames++;
              return f.missedFrames < 15; // å¤šäººæ¨¡å¼å®¹å¿åº¦ä½ä¸€ç‚¹
          }
          return true;
      });

      // ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šåªä¿ç•™ Top N (æŒ‰è„¸çš„å¤§å°æ’åº)
      // é˜²æ­¢èƒŒæ™¯å™ªç‚¹å˜æˆ Emoji
      trackedFaces.sort((a, b) => (b.w * b.h) - (a.w * a.h)); // é¢ç§¯ä»å¤§åˆ°å°
      if (trackedFaces.length > maxN) {
          trackedFaces = trackedFaces.slice(0, maxN);
      }

      multiFacesRef.current = trackedFaces;
  };

  // ç»Ÿä¸€ç»˜åˆ¶å‡½æ•°
  const drawFaces = (ctx, faces, mode, emoji) => {
      const scale = 1.5;
      faces.forEach(face => {
          if (!face) return;
          const { x, y, w, h } = face;
          
          if (mode === 'image' && maskImgRef.current) {
              const dw = w * scale;
              const dh = h * scale;
              ctx.drawImage(maskImgRef.current, x - (dw-w)/2, y - (dh-h)/2, dw, dh);
          } else {
              const fontSize = Math.max(w, h) * scale;
              ctx.font = `${fontSize}px "Apple Color Emoji", "Segoe UI Emoji", sans-serif`;
              ctx.textAlign = 'center';
              ctx.textBaseline = 'middle';
              ctx.fillText(emoji, x + w/2, y + h/2 + h*0.1);
          }
      });
  };

  return (
    <div style={containerStyle}>
      <h2 style={{textAlign: 'center'}}>ä¿æŠ¤è±†ç§ (ç»ˆæç‰ˆ)</h2>
      
      {/* æ§åˆ¶é¢æ¿ */}
      <div style={controlPanelStyle}>
        
        {/* 1. æ¨¡å¼é€‰æ‹© */}
        <div>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>ğŸ¯ è¿½è¸ªæ¨¡å¼</label>
            <div style={{display: 'flex', gap: '10px', marginBottom: '10px'}}>
                <button 
                    onClick={() => setTrackingMode('single')}
                    style={{
                        ...buttonStyle,
                        background: trackingMode === 'single' ? '#007bff' : '#fff',
                        color: trackingMode === 'single' ? '#fff' : '#333',
                        border: '1px solid #ccc'
                    }}
                >
                    ğŸ‘¤ å•äººæ­»é” (æ¨è)
                </button>
                <button 
                    onClick={() => setTrackingMode('multi')}
                    style={{
                        ...buttonStyle,
                        background: trackingMode === 'multi' ? '#6610f2' : '#fff',
                        color: trackingMode === 'multi' ? '#fff' : '#333',
                        border: '1px solid #ccc'
                    }}
                >
                    ğŸ‘¥ å¤šäºº Top-N
                </button>
            </div>
            
            {/* å¤šäººæ¨¡å¼ä¸‹çš„è®¾ç½® */}
            {trackingMode === 'multi' && (
                <div style={{display: 'flex', alignItems: 'center', gap: '10px', fontSize: '14px', background: '#fff', padding: '8px', borderRadius: '6px'}}>
                    <span>åªç»™æœ€å¤§çš„å‰</span>
                    <input 
                        type="number" min="1" max="10" 
                        value={maxFaces} 
                        onChange={(e) => setMaxFaces(parseInt(e.target.value))}
                        style={{width: '50px', padding: '5px', textAlign: 'center', border: '1px solid #ccc', borderRadius: '4px'}}
                    />
                    <span>äººæ‰“ç  (é˜²æ­¢ä¹±ç )</span>
                </div>
            )}
            
            <p style={{fontSize: '12px', color: '#666', marginTop: '5px'}}>
                {trackingMode === 'single' 
                    ? 'å•äººæ¨¡å¼ï¼šåªè¿½è¸ªç”»é¢é‡Œæœ€å¤§çš„ä¸€å¼ è„¸ï¼Œæ— è§†èƒŒæ™¯è·¯äººï¼Œæ•ˆæœæœ€ç¨³ã€‚' 
                    : `å¤šäººæ¨¡å¼ï¼šä¼šè¿½è¸ªç”»é¢é‡Œæœ€å¤§çš„ ${maxFaces} ä¸ªäººï¼Œå¤šä½™çš„æ‚ä¹±äººè„¸ä¼šè¢«è¿‡æ»¤ã€‚`}
            </p>
        </div>

        {/* 2. å¯¼å‡ºæ ¼å¼ */}
        <div>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>ğŸ’¾ å¯¼å‡ºæ ¼å¼</label>
            <select 
                value={exportFormat} 
                onChange={(e) => setExportFormat(e.target.value)}
                style={{...inputStyle, background: '#fff'}}
            >
                <option value="mp4">MP4 (æ¨èæ‰‹æœº/iOS)</option>
                <option value="webm">WebM (æ¨èç”µè„‘/å®‰å“)</option>
            </select>
        </div>

        {/* 3. è§†é¢‘å’Œç´ æ */}
        <div>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>ğŸ“¹ å¯¼å…¥è§†é¢‘</label>
            <input type="file" accept="video/*" onChange={handleVideoUpload} style={{...inputStyle, background: '#fff'}} />
        </div>

        <div>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>ğŸ­ é®æŒ¡æ–¹å¼</label>
            <div style={{display: 'flex', gap: '10px', marginBottom: '10px'}}>
                <label style={{cursor: 'pointer', display: 'flex', alignItems: 'center'}}>
                    <input type="radio" name="maskMode" value="emoji" checked={maskMode === 'emoji'} onChange={(e) => setMaskMode(e.target.value)} style={{marginRight: '5px'}} /> Emoji
                </label>
                <label style={{cursor: 'pointer', display: 'flex', alignItems: 'center'}}>
                    <input type="radio" name="maskMode" value="image" checked={maskMode === 'image'} onChange={(e) => setMaskMode(e.target.value)} style={{marginRight: '5px'}} /> å›¾ç‰‡
                </label>
            </div>
            {maskMode === 'emoji' ? (
                <input type="text" value={emojiChar} placeholder="è¾“å…¥Emoji" onChange={(e) => setEmojiChar(e.target.value)} maxLength={5} style={{...inputStyle, fontSize: '32px', textAlign: 'center', background: '#fff'}} />
            ) : (
                <input type="file" accept="image/*" onChange={handleMaskUpload} style={{...inputStyle, background: '#fff'}} />
            )}
        </div>

      </div>

      <div style={{border: '2px solid #333', borderRadius: '8px', background: '#000', minHeight: '200px', display: 'flex', justifyContent: 'center', alignItems: 'center', overflow: 'hidden', marginBottom: '20px'}}>
        <canvas ref={canvasRef} style={{maxWidth: '100%', maxHeight: '60vh', display: 'block'}} />
      </div>

      <div style={{display: 'flex', justifyContent: 'center', gap: '15px'}}>
        <button style={{...buttonStyle, opacity: (isProcessing || !videoSrc) ? 0.6 : 1}} onClick={startProcessing} disabled={isProcessing || !videoSrc}>
          {isProcessing ? 'â³ å¤„ç†ä¸­...' : 'ğŸš€ å¼€å§‹ç”Ÿæˆ'}
        </button>
        {downloadUrl && (
          <a href={downloadUrl} download={`masked_${Date.now()}.${exportFormat}`} style={{...buttonStyle, background: '#28a745', textDecoration: 'none', display: 'flex', alignItems: 'center', justifyContent: 'center'}}>
            ğŸ’¾ ä¿å­˜ ({exportFormat.toUpperCase()})
          </a>
        )}
      </div>
      
      {/* éšè—çš„ Video */}
      <video ref={videoRef} src={videoSrc} style={{position: 'fixed', opacity: 0, pointerEvents: 'none'}} playsInline webkit-playsinline="true" crossOrigin="anonymous" />
    </div>
  );
}

export default App;