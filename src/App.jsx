import React, { useState, useRef, useEffect } from 'react';
import { FaceDetector, FilesetResolver } from '@mediapipe/tasks-vision';

const containerStyle = { maxWidth: '600px', margin: '0 auto', padding: '20px', fontFamily: '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif' };
const buttonStyle = { padding: '12px 24px', margin: '5px', background: '#007bff', color: '#fff', border: 'none', borderRadius: '8px', fontSize: '16px', fontWeight: 'bold', cursor: 'pointer' };
const inputStyle = { padding: '10px', borderRadius: '8px', border: '1px solid #ccc', width: '100%', boxSizing: 'border-box', fontSize: '16px' };

function App() {
  const [fileExt, setFileExt] = useState("webm"); 
  const [detector, setDetector] = useState(null);
  const [videoSrc, setVideoSrc] = useState(null);
  
  // ğŸ”¥ æ–°å¢ï¼šé®æŒ¡æ¨¡å¼çŠ¶æ€ ('image' æˆ– 'emoji')
  const [maskMode, setMaskMode] = useState('emoji'); 
  const [maskSrc, setMaskSrc] = useState(null); // å›¾ç‰‡æº
  const [emojiChar, setEmojiChar] = useState('ğŸ˜'); // Emoji å­—ç¬¦

  const [isProcessing, setIsProcessing] = useState(false);
  const [status, setStatus] = useState("æ­£åœ¨åŠ è½½ AI æ¨¡å‹...");
  const [downloadUrl, setDownloadUrl] = useState(null);

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const maskImgRef = useRef(null);
  const chunksRef = useRef([]);
  const lastFaceRef = useRef(null);
  const velocityRef = useRef({ x: 0, y: 0 });

  // ğŸ”¥ æ–°å¢ï¼šä½¿ç”¨ Ref æ¥åœ¨å¾ªç¯ä¸­è¯»å–æœ€æ–°çš„ Emoji å’Œæ¨¡å¼ï¼Œé˜²æ­¢é—­åŒ…é—®é¢˜
  const emojiRef = useRef('ğŸ˜');
  const maskModeRef = useRef('emoji');

  const audioCtxRef = useRef(null);
  const sourceNodeRef = useRef(null);
  const destNodeRef = useRef(null);
  const initLockRef = useRef(false);

  useEffect(() => {
    if (initLockRef.current === true) return;
    initLockRef.current = true;

    const initAI = async () => {
      console.log("ğŸš€ å¼€å§‹åˆå§‹åŒ– AI æ¨¡å‹...");
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        const faceDetector = await FaceDetector.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          minDetectionConfidence: 0.3,
          minSuppressionThreshold: 0.3 
        });
        setDetector(faceDetector);
        setStatus("âœ… AI å°±ç»ªï¼è¯·å¯¼å…¥è§†é¢‘");
      } catch (err) {
        setStatus(`âŒ æ¨¡å‹åŠ è½½å¤±è´¥: ${err.message}`);
      }
    };
    initAI();
  }, []);

  // æ›´æ–° Ref å½“çŠ¶æ€æ”¹å˜æ—¶
  useEffect(() => {
    emojiRef.current = emojiChar;
    maskModeRef.current = maskMode;
  }, [emojiChar, maskMode]);

  const handleVideoUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
      setVideoSrc(URL.createObjectURL(file));
      setDownloadUrl(null);
      setStatus("è§†é¢‘å·²åŠ è½½");
    }
  };

  const handleMaskUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
      const img = new Image();
      img.src = URL.createObjectURL(file);
      img.onload = () => { maskImgRef.current = img; };
      setMaskSrc(img.src);
    }
  };

  const startProcessing = async () => {
    // æ£€æŸ¥é€»è¾‘ï¼šå¦‚æœæ˜¯å›¾ç‰‡æ¨¡å¼ï¼Œå¿…é¡»æœ‰å›¾ç‰‡ï¼›å¦‚æœæ˜¯ Emoji æ¨¡å¼ï¼Œä¸éœ€è¦å›¾ç‰‡
    if (!detector || !videoRef.current) {
      alert("è¯·ç¡®ä¿è§†é¢‘å’ŒAIæ¨¡å‹å·²å°±ç»ª");
      return;
    }
    if (maskMode === 'image' && !maskImgRef.current) {
        alert("è¯·å…ˆä¸Šä¼ é®æŒ¡å›¾ç‰‡");
        return;
    }

    const video = videoRef.current;
    if (video.readyState < 2) {
        setStatus("æ­£åœ¨ç¼“å†²è§†é¢‘...");
        await new Promise(resolve => {
            video.onloadeddata = resolve;
            setTimeout(resolve, 1500); 
        });
    }

    setIsProcessing(true);
    setStatus("æ­£åœ¨åˆå§‹åŒ–...");
    setDownloadUrl(null);
    chunksRef.current = [];
    lastFaceRef.current = null;
    velocityRef.current = { x: 0, y: 0 };

    const canvas = canvasRef.current;
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;
    const ctx = canvas.getContext('2d');

    // === éŸ³é¢‘å¤„ç† ===
    try {
        if (!audioCtxRef.current) audioCtxRef.current = new (window.AudioContext || window.webkitAudioContext)();
        const audioCtx = audioCtxRef.current;
        if (audioCtx.state === 'suspended') await audioCtx.resume();
        if (sourceNodeRef.current) try { sourceNodeRef.current.disconnect(); } catch(e){}
        sourceNodeRef.current = audioCtx.createMediaElementSource(video);
        if (!destNodeRef.current) destNodeRef.current = audioCtx.createMediaStreamDestination();
        sourceNodeRef.current.connect(destNodeRef.current);
    } catch (e) { console.warn("éŸ³é¢‘è­¦å‘Š:", e); }

    const canvasStream = canvas.captureStream(30); 
    if (destNodeRef.current) {
        const audioTrack = destNodeRef.current.stream.getAudioTracks()[0];
        if (audioTrack) canvasStream.addTrack(audioTrack);
    }

    // æ ¼å¼é€‰æ‹©
    const options = [
        { mimeType: 'video/webm; codecs=vp9', ext: 'webm' },
        { mimeType: 'video/webm', ext: 'webm' },
        { mimeType: 'video/mp4; codecs="avc1.42E01E, mp4a.40.2"', ext: 'mp4' },
        { mimeType: 'video/mp4', ext: 'mp4' }
    ];
    let selectedOption = options.find(opt => MediaRecorder.isTypeSupported(opt.mimeType)) || { mimeType: '', ext: 'webm' };
    setFileExt(selectedOption.ext);

    let recorder;
    try {
        recorder = new MediaRecorder(canvasStream, { mimeType: selectedOption.mimeType, videoBitsPerSecond: 2500000 });
    } catch (e) { recorder = new MediaRecorder(canvasStream); }
    
    recorder.ondataavailable = (e) => { if (e.data && e.data.size > 0) chunksRef.current.push(e.data); };
    recorder.onstop = () => {
      const blob = new Blob(chunksRef.current, { type: selectedOption.mimeType || 'video/webm' });
      if (blob.size === 0) { alert("ç”Ÿæˆå¤±è´¥ï¼šæ–‡ä»¶å¤§å°ä¸º0"); setIsProcessing(false); return; }
      setDownloadUrl(URL.createObjectURL(blob));
      setIsProcessing(false);
      setStatus("âœ… å¤„ç†å®Œæˆï¼");
      video.pause(); video.muted = false;
      canvasStream.getTracks().forEach(track => track.stop());
    };

    recorder.start(100); 
    
    try {
        video.currentTime = 0; video.muted = false; 
        await video.play();
        processFrame(video, ctx, recorder);
    } catch (e) {
        console.error("æ’­æ”¾å¤±è´¥:", e);
        setStatus(`æ’­æ”¾é”™è¯¯: ${e.message}`);
        setIsProcessing(false);
        recorder.stop();
    }
  };

  const processFrame = (video, ctx, recorder) => {
    if (video.ended || video.paused) {
      if (recorder.state === 'recording') recorder.stop();
      return;
    }

    const canvas = ctx.canvas;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const startTimeMs = performance.now();
    let detections = null;
    try { if (detector) detections = detector.detectForVideo(video, startTimeMs).detections; } catch(e) {}

    let targetFace = null;

    if (detections && detections.length > 0) {
      const face = detections[0].boundingBox;
      if (lastFaceRef.current) {
         velocityRef.current = { x: face.originX - lastFaceRef.current.originX, y: face.originY - lastFaceRef.current.originY };
      }
      targetFace = face;
      lastFaceRef.current = face;
    } else if (lastFaceRef.current) {
      const vx = velocityRef.current.x * 0.9;
      const vy = velocityRef.current.y * 0.9;
      const predictedFace = { ...lastFaceRef.current, originX: lastFaceRef.current.originX + vx, originY: lastFaceRef.current.originY + vy };
      velocityRef.current = { x: vx, y: vy };
      targetFace = predictedFace;
      lastFaceRef.current = predictedFace; 
    }

    // ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ ¹æ®æ¨¡å¼ç»˜åˆ¶
    if (targetFace) {
      const { originX, originY, width, height } = targetFace;
      const currentMode = maskModeRef.current;
      const scale = 1.5; 

      if (currentMode === 'image' && maskImgRef.current) {
          // å›¾ç‰‡ç»˜åˆ¶é€»è¾‘ (ä¿æŒä¸å˜)
          const w = width * scale;
          const h = height * scale;
          const x = originX - (w - width) / 2;
          const y = originY - (h - height) / 2;
          ctx.drawImage(maskImgRef.current, x, y, w, h);
      } else if (currentMode === 'emoji') {
          // ğŸ”¥ Emoji ç»˜åˆ¶é€»è¾‘
          const currentEmoji = emojiRef.current;
          
          // 1. è®¾ç½®å­—ä½“ï¼šå¤§å°è·Ÿéšäººè„¸é«˜åº¦å˜åŒ–
          // ä¸ºäº†è®© Emoji è¦†ç›–ä½è„¸ï¼Œå­—ä½“å¤§å°è®¾ä¸ºäººè„¸æœ€å¤§è¾¹é•¿çš„ 1.5 å€
          const fontSize = Math.max(width, height) * scale;
          
          // 2. å…³é”®ï¼šæŒ‡å®š "Apple Color Emoji" ç¡®ä¿ iOS ä¸Šæ˜¾ç¤ºä¸ºå½©è‰²åŸç”Ÿ Emoji
          ctx.font = `${fontSize}px "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", sans-serif`;
          
          // 3. å¯¹é½æ–¹å¼ï¼šå±…ä¸­
          ctx.textAlign = 'center';
          ctx.textBaseline = 'middle';
          
          // 4. è®¡ç®—ä¸­å¿ƒç‚¹
          const centerX = originX + width / 2;
          const centerY = originY + height / 2;
          
          // 5. ç»˜åˆ¶æ–‡å­— (Emoji ç¨å¾®å¾€ä¸‹ä¸€ç‚¹ç‚¹é€šå¸¸è§†è§‰ä¸Šæ›´å±…ä¸­ï¼Œæ‰€ä»¥ + height*0.1)
          ctx.fillText(currentEmoji, centerX, centerY + (height * 0.1));
      }
    }

    requestAnimationFrame(() => processFrame(video, ctx, recorder));
  };

  return (
    <div style={containerStyle}>
      <h2 style={{textAlign: 'center'}}>ä¿æŠ¤è±†ç§ (Emoji ç‰ˆ)</h2>
      <p style={{textAlign: 'center', color: isProcessing ? '#d9534f' : '#666', fontWeight: isProcessing ? 'bold' : 'normal'}}>
        {status}
      </p>

      <div style={{background: '#f8f9fa', padding: '15px', borderRadius: '10px', marginBottom: '20px', boxShadow: '0 2px 5px rgba(0,0,0,0.05)'}}>
        <div style={{marginBottom: '15px'}}>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>1. å¯¼å…¥è§†é¢‘ ğŸ“¹</label>
            <input type="file" accept="video/*" onChange={handleVideoUpload} style={inputStyle} />
        </div>
        
        <div style={{marginBottom: '10px'}}>
            <label style={{display: 'block', fontWeight: 'bold', marginBottom: '8px'}}>2. é€‰æ‹©é®æŒ¡æ–¹å¼ ğŸ­</label>
            <div style={{display: 'flex', gap: '20px', marginBottom: '10px'}}>
                <label style={{cursor: 'pointer', display: 'flex', alignItems: 'center'}}>
                    <input 
                        type="radio" 
                        name="maskMode" 
                        value="emoji" 
                        checked={maskMode === 'emoji'} 
                        onChange={(e) => setMaskMode(e.target.value)}
                        style={{marginRight: '5px'}}
                    />
                    ä½¿ç”¨ Emoji (æ¨è âœ¨)
                </label>
                <label style={{cursor: 'pointer', display: 'flex', alignItems: 'center'}}>
                    <input 
                        type="radio" 
                        name="maskMode" 
                        value="image" 
                        checked={maskMode === 'image'} 
                        onChange={(e) => setMaskMode(e.target.value)}
                        style={{marginRight: '5px'}}
                    />
                    ä¸Šä¼ å›¾ç‰‡
                </label>
            </div>

            {/* æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒçš„è¾“å…¥æ¡† */}
            {maskMode === 'emoji' ? (
                <div>
                    <input 
                        type="text" 
                        value={emojiChar}
                        placeholder="åœ¨æ­¤è¾“å…¥ Emojiï¼Œä¾‹å¦‚ ğŸƒ" 
                        onChange={(e) => setEmojiChar(e.target.value)}
                        maxLength={5} // é˜²æ­¢è¾“å…¥å¤ªé•¿
                        style={{
                            ...inputStyle, 
                            fontSize: '32px', 
                            textAlign: 'center', 
                            letterSpacing: '5px'
                        }}
                    />
                    <p style={{fontSize: '12px', color: '#666', marginTop: '5px'}}>
                        æç¤ºï¼šåœ¨æ‰‹æœºä¸Šç‚¹å‡»è¾“å…¥æ¡†ï¼Œä½¿ç”¨é”®ç›˜è‡ªå¸¦çš„è¡¨æƒ…è¾“å…¥æ³•å³å¯ã€‚
                    </p>
                </div>
            ) : (
                <input type="file" accept="image/*" onChange={handleMaskUpload} style={inputStyle} />
            )}
        </div>
      </div>

      <video 
        ref={videoRef} 
        src={videoSrc} 
        style={{ position: 'fixed', top: 0, left: 0, opacity: 0, pointerEvents: 'none', zIndex: -1, width: '1px', height: '1px' }} 
        playsInline 
        webkit-playsinline="true"
        crossOrigin="anonymous"
      />

      <div style={{ 
          border: '2px solid #333', 
          borderRadius: '8px',
          background: '#000', 
          minHeight: '200px', 
          display: 'flex', 
          justifyContent: 'center', 
          alignItems: 'center',
          overflow: 'hidden',
          marginBottom: '20px'
      }}>
        <canvas ref={canvasRef} style={{ maxWidth: '100%', maxHeight: '60vh', display: 'block' }} />
      </div>

      <div style={{ display: 'flex', justifyContent: 'center', gap: '15px', flexWrap: 'wrap' }}>
        <button 
          style={{...buttonStyle, opacity: (isProcessing || !videoSrc) ? 0.6 : 1, width: '100%'}} 
          onClick={startProcessing} 
          disabled={isProcessing || !videoSrc}
        >
          {isProcessing ? 'â³ å¤„ç†ä¸­...' : 'ğŸš€ å¼€å§‹ç”Ÿæˆ'}
        </button>

        {downloadUrl && (
          <a 
            href={downloadUrl} 
            download={`masked_video_${Date.now()}.${fileExt}`}
            style={{...buttonStyle, background: '#28a745', textDecoration: 'none', display: 'flex', alignItems: 'center', justifyContent: 'center', width: '100%'}}
          >
            ğŸ’¾ ä¿å­˜åˆ°ç›¸å†Œ ({fileExt.toUpperCase()})
          </a>
        )}
      </div>
    </div>
  );
}

export default App;